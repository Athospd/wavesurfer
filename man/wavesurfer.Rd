% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wavesurfer.R
\name{wavesurfer}
\alias{wavesurfer}
\title{Create a soundwave visualization}
\usage{
wavesurfer(audio = NULL, playPauseWithSpaceBar = TRUE, audioRate = 1,
  autoCenter = TRUE, backgroundColor = NULL, barHeight = 1,
  barGap = NULL, barWidth = NULL, cursorColor = "#333",
  fillParent = TRUE, forceDecode = FALSE, hideScrollbar = FALSE,
  interact = TRUE, loopSelection = TRUE, maxCanvasWidth = 4000,
  minPxPerSec = 20, normalize = FALSE, progressColor = "#555",
  responsive = FALSE, scrollParent = FALSE, skipLength = 2,
  splitChannels = FALSE, waveColor = "#999", width = NULL,
  height = NULL, elementId = NULL, annotations = NULL,
  visualization = "wave")
}
\arguments{
\item{audio}{a character. A path or a URL for the audio. E.g. "path/to/audio.mp3"
or "https://wavesurfer-js.org/example/media/demo.wav".}

\item{playPauseWithSpaceBar}{a logical. If TRUE, spacebar toggle play/pause. Default is TRUE.}

\item{audioRate}{a numeric. Speed at which to play audio. Lower number is
slower. Default is 1.}

\item{autoCenter}{If a scrollbar is present, center the waveform around the
progress. Defaults to TRUE.}

\item{backgroundColor}{todo.}

\item{barHeight}{a numeric. Height of the waveform bars. Higher number than 1
will increase the waveform bar heights. Default is 1.}

\item{barGap}{a numeric. The optional spacing between bars of the wave.}

\item{barWidth}{a numeric. If specified, the waveform will be drawn like
this: ▁ ▂ ▇ ▃ ▅ ▂}

\item{cursorColor}{a character. The fill color of the cursor indicating the playhead
position. Default is '#333333'.}

\item{fillParent}{a logical. Whether to fill the entire container or draw only
according to minPxPerSec. Defaults to TRUE.}

\item{forceDecode}{a logical. Force decoding of audio using web audio when
zooming to get a more detailed waveform. Defaults to FALSE.}

\item{hideScrollbar}{a logical. Whether to hide the horizontal scrollbar when one
would normally be shown. Defaults to FALSE.}

\item{interact}{a logical. Whether the mouse interaction will be enabled at
initialization. Defaults to TRUE.}

\item{loopSelection}{a logical. (Use with regions plugin) Enable looping of selected
regions. Defaults to TRUE.}

\item{maxCanvasWidth}{a numeric. Maximum width of a single canvas in pixels, excluding
a small overlap (`2 * pixelRatio`,
rounded up to the next even integer). If the waveform is longer than this value,
additional canvases will be used to render the waveform, which is useful for very
large waveforms that may be too wide for browsers to draw on a single canvas. This
parameter is only applicable to the `MultiCanvas` renderer.}

\item{minPxPerSec}{a numeric. Minimum number of pixels per second of audio.
Default is 50.}

\item{normalize}{a logical. If TRUE, normalize by the maximum peak instead of 1.}

\item{progressColor}{a character. The fill color of the part of the waveform
behind the cursor. When `progressColor` and `waveColor` are
the same the progress wave is not rendered at all. Default is '#555555'.}

\item{responsive}{a logical. If set to TRUE resize the waveform, when
the window is resized. This is debounced with a 100ms timeout by default.
If this parameter is a number it represents that timeout.}

\item{scrollParent}{a logical. Whether to scroll the container with a
lengthy waveform. Otherwise the waveform is shrunk to the container width
(see `fillParent`). Defaults to FALSE.}

\item{skipLength}{a numeric. Number of seconds to skip with the
\code{\link[wavesurfer]{ws_skip_forward}} and \code{\link[wavesurfer]{ws_skip_backward}}
functions. Default is 2 seconds.}

\item{splitChannels}{a logical. Render with seperate waveforms for the
channels of the audio. Defaults to FALSE.}

\item{waveColor}{a character. The fill color of the waveform after the
cursor. Default is '#999999'.}

\item{width}{Fixed width for timeline (in css units).}

\item{height}{Fixed height for timeline (in css units).}

\item{elementId}{Use an explicit element ID for the widget (rather than an
automatically generated one). Ignored when used in a Shiny app.}

\item{annotations}{a data.frame with columns "sound_id" (character), "region_id"
(character), "start" (numeric), "end" (numeric), "label" (character). The rows
represents the annotated regions of the audio.}

\item{visualization}{a character. Either 'wave' or 'spectrogram'. The type of
the main visualization. Default is 'wave'.}

\item{rtl}{todo.}
}
\value{
A wavesurfer visualization \code{htmlwidgets} object
}
\description{
\code{wavesurfer} is an interactive soundwave player and visualizer with rich set of
plugins and tools. It works well with pipe (%>%) and can be used in Shiny. It is an interface of \href{https://wavesurfer-js.org}{'wavesurfer.js'}
JavaScript library and it is based on \href{http://www.htmlwidgets.org/}{'htmlwidgets'} R package.
}
\details{
See also \href{https://wavesurfer-js.org/docs/options.html}{https://wavesurfer-js.org/docs/options.html}
for the original JS documentation.
}
\section{Plugins}{

The following plugins are implemented:
\itemize{
  \item{\strong{\code{\link[wavesurfer]{ws_regions}}}} - Adds ability to display
  and interact with audio regions. Regions are visual overlays that can be resized
  and dragged around the waveform. See also \strong{\code{\link[wavesurfer]{ws_annotator}}}
  for a nice feature to annotate regions with ease.
  \item{\strong{\code{\link[wavesurfer]{ws_timeline}}}} - Adds a nice simple timeline to
  your waveform. By \href{https://github.com/instajams}{Instajams}.
  \item{\strong{\code{\link[wavesurfer]{ws_minimap}}}} - Adds a minimap preview of your waveform. By \href{https://github.com/entonbiba}{Enton Biba}.
  \item{\strong{\code{\link[wavesurfer]{ws_spectrogram}}}} - Shows a spectrogram for your waveform right below it.
  \item{\strong{\code{\link[wavesurfer]{ws_cursor}}}} - Shows a cursor on your waveform.
  \item{\strong{\code{\link[wavesurfer]{ws_microphone}}}} - Visualizes audio input from a microphone. By \href{https://github.com/thijstriemstra}{Thijs Triemstra}.
}
}

\examples{
if (interactive()) {

  library(wavesurfer)

  # set the folders of input wavs and output annotations
  wav_folder <- system.file("wav", package = "wavesurfer")
  annotation_folder <- tempdir()

  # make it available to shiny
  shiny::addResourcePath("wav", wav_folder)

  # Define UI for application that draws a histogram
  ui <- fluidPage(

    # Application title
    titlePanel("Anotador"),

    uiOutput("wav_files"),

    actionButton("minimap", "Minimap", icon = icon("map")),
    actionButton("spectrogram", "spectrogram", icon = icon("chart")),
    tags$br(),
    wavesurferOutput("my_ws"),
    tags$br(),
    actionButton("play", "Play", icon = icon("play")),
    actionButton("pause", "Pause", icon = icon("pause")),
    actionButton("mute", "Mute", icon = icon("times")),
    actionButton("stop", "Stop", icon = icon("stop")),
    actionButton("save", "Save", icon = icon("save")),
    actionButton("suggest_regions", "Suggest regions", icon = icon("cut")),
    tags$br(),
    sliderInput("zoom", "Zoom", min = 1, max = 1000, value = 50),
    tags$br(),
    verbatimTextOutput("regions"),
    verbatimTextOutput("current_region"),
    verbatimTextOutput("inputs_available")
  )

  # Define server logic required to draw a histogram
  server <- function(input, output, session) {

    wav_name <- reactive({
      stringr::str_replace(input$audio, "^wav/", "")
    })

    output$wav_files <- renderUI({
      selectizeInput(
        "audio", "Audio: ", width = "100\%",
        choices = list.files(wav_folder)
      )
    })

    output$my_ws <- renderWavesurfer({
      req(!is.null(input$audio))

      # look if there is regions already annotated
      annotations_file <- stringr::str_replace_all(stringr::str_replace_all(input$audio, "wav$", "rds"), "^.*/", "")
      annotations_file <- paste0(annotation_folder, annotations_file)
      if(file.exists(annotations_file)) {
        annotations_df <- readr::read_rds(annotations_file)
      } else {
        annotations_df <- NULL
      }

      wavesurfer(
        paste0("wav/",input$audio),
        annotations = annotations_df,
        waveColor = "#cc33aa",
        visualization = 'spectrogram'
      ) \%>\%
        ws_annotator()
    })

    # controllers
    observeEvent(input$play, {ws_play("my_ws")})
    observeEvent(input$pause, {ws_pause("my_ws")})
    observeEvent(input$mute, {ws_toggle_mute("my_ws")})
    observeEvent(input$stop, {ws_stop("my_ws")})
    observeEvent(input$minimap, {ws_minimap("my_ws")})
    observeEvent(input$spectrogram, {ws_spectrogram("my_ws")})
    observeEvent(input$regions, {ws_regions("my_ws")})
    observe({ws_zoom("my_ws", input$zoom)})

    observeEvent(input$save, {
      req(!is.null(wav_name()))

      annotations <- stringr::str_replace_all(wav_name(), "wav$", "rds")
      regions <- input$my_ws_regions \%>\% dplyr::mutate(sound_id = wav_name())
      readr::write_rds(x = regions, path = paste0(annotation_folder, "/", annotations))
    })

    observeEvent(input$suggest_regions, {

      wav <- tuneR::readWave(paste0(wav_folder, "/", wav_name()))

      ## funcao do auto detector
      auto_detect_partial <- purrr::partial(
        warbleR::auto_detec,
        X = data.frame(sound.files = wav_name(), selec = 1, start = 0, end = Inf),
        path = wav_folder,
        pb = FALSE
      )
      especies <- stringr::str_remove(wav_name(), "-[0-9]*\\\\.wav$")
      auto_detect_parameters <- wavesurfer::birds$auto_detect_parameters[[especies]]

      ## segments founded
      suggested_annotations <- do.call(auto_detect_partial, auto_detect_parameters)
      suggested_annotations$sound.files <- wav_name()

      if(is.null(suggested_annotations$label)) {
        suggested_annotations$label <- "(suggested region)"
      }

      names(suggested_annotations) <- c("sound_id", "region_id", "start", "end", "label")
      ws_add_regions("my_ws", suggested_annotations)
    })

    output$current_region <- renderPrint({
      input$my_ws_selected_region
    })

    output$regions <- renderPrint({
      input$my_ws_regions
    })

    output$inputs_available <- renderPrint({
      reactiveValuesToList(input)
    })
  }

  shinyApp(ui = ui, server = server)
}

}
